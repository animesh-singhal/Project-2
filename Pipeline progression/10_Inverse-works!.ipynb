{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ye ab tak ka code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def process_image(frame):\n",
    "    \n",
    "    def cal_undistort(img):\n",
    "        # Reads mtx and dist matrices, peforms image distortion correction and returns the undistorted image\n",
    "\n",
    "        import pickle\n",
    "\n",
    "        # Read in the saved matrices\n",
    "        my_dist_pickle = pickle.load( open( \"output_files/calib_pickle_files/dist_pickle.p\", \"rb\" ) )\n",
    "        mtx = my_dist_pickle[\"mtx\"]\n",
    "        dist = my_dist_pickle[\"dist\"]\n",
    "\n",
    "        img_size = (img.shape[1], img.shape[0])    \n",
    "\n",
    "        undistorted_img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        #undistorted_img =  cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)   #Use if you use cv2 to import image. ax.imshow() needs RGB image\n",
    "        return undistorted_img\n",
    "\n",
    "    \n",
    "    def yellow_threshold(img, sxbinary):\n",
    "        # Convert to HLS color space and separate the S channel\n",
    "        # Note: img is the undistorted image\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        s_channel = hls[:,:,2]\n",
    "        h_channel = hls[:,:,0]\n",
    "        # Threshold color channel\n",
    "        s_thresh_min = 100\n",
    "        s_thresh_max = 255\n",
    "        \n",
    "        #for 360 degree, my value for yellow ranged between 35 and 50. So uska half kar diya\n",
    "        h_thresh_min = 10    \n",
    "        h_thresh_max = 25\n",
    "\n",
    "        s_binary = np.zeros_like(s_channel)\n",
    "        s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "\n",
    "        h_binary = np.zeros_like(h_channel)\n",
    "        h_binary[(h_channel >= h_thresh_min) & (h_channel <= h_thresh_max)] = 1\n",
    "\n",
    "        # Combine the two binary thresholds\n",
    "        yellow_binary = np.zeros_like(s_binary)\n",
    "        yellow_binary[(((s_binary == 1) | (sxbinary == 1) ) & (h_binary ==1))] = 1\n",
    "        return yellow_binary\n",
    "    \n",
    "    def xgrad_binary(img, thresh_min=30, thresh_max=100):\n",
    "        # Grayscale image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # Sobel x\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "        abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "        scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "        # Threshold x gradient\n",
    "        #thresh_min = 30    #Already given above\n",
    "        #thresh_max = 100\n",
    "\n",
    "        sxbinary = np.zeros_like(scaled_sobel)\n",
    "        sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "        return sxbinary\n",
    "    \n",
    "    def white_threshold(img, sxbinary, lower_white_thresh = 170):\n",
    "        r_channel = img[:,:,0]\n",
    "        g_channel = img[:,:,1]\n",
    "        b_channel = img[:,:,2]\n",
    "        # Threshold color channel\n",
    "        r_thresh_min = lower_white_thresh\n",
    "        r_thresh_max = 255\n",
    "        r_binary = np.zeros_like(r_channel)\n",
    "        r_binary[(r_channel >= r_thresh_min) & (r_channel <= r_thresh_max)] = 1\n",
    "        \n",
    "        g_thresh_min = lower_white_thresh\n",
    "        g_thresh_max = 255\n",
    "        g_binary = np.zeros_like(g_channel)\n",
    "        g_binary[(g_channel >= g_thresh_min) & (g_channel <= g_thresh_max)] = 1\n",
    "\n",
    "        b_thresh_min = lower_white_thresh\n",
    "        b_thresh_max = 255\n",
    "        b_binary = np.zeros_like(b_channel)\n",
    "        b_binary[(b_channel >= b_thresh_min) & (b_channel <= b_thresh_max)] = 1\n",
    "\n",
    "        white_binary = np.zeros_like(r_channel)\n",
    "        white_binary[((r_binary ==1) & (g_binary ==1) & (b_binary ==1) & (sxbinary==1))] = 1\n",
    "        return white_binary\n",
    "        \n",
    "    def thresh_img(img):\n",
    "                       \n",
    "       \n",
    "        #sxbinary = xgrad_binary(img, thresh_min=30, thresh_max=100)\n",
    "        sxbinary = xgrad_binary(img, thresh_min=25, thresh_max=130)\n",
    "        yellow_binary = yellow_threshold(img, sxbinary)     #(((s) | (sx)) & (h))\n",
    "        white_binary = white_threshold(img, sxbinary, lower_white_thresh = 150)\n",
    "        \n",
    "        # Combine the two binary thresholds\n",
    "        combined_binary = np.zeros_like(sxbinary)\n",
    "        combined_binary[((yellow_binary == 1) | (white_binary == 1))] = 1\n",
    "        \n",
    "        out_img = np.dstack((combined_binary, combined_binary, combined_binary))*255\n",
    "        \n",
    "        return out_img\n",
    "    \n",
    "    def perspective_transform(img):\n",
    "    \n",
    "        # Define calibration box in source (original) and destination (desired or warped) coordinates\n",
    "\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        \"\"\"Notice the format used for img_size. Yaha bhi ulta hai. x axis aur fir y axis chahiye. \n",
    "              Apne format mein rows(y axis) and columns (x axis) hain\"\"\"\n",
    "\n",
    "\n",
    "        # Four source coordinates\n",
    "        # Order of points: top left, top right, bottom right, bottom left\n",
    "        \n",
    "        src = np.array(\n",
    "            [[435*img.shape[1]/960, 350*img.shape[0]/540],\n",
    "             [530*img.shape[1]/960, 350*img.shape[0]/540],\n",
    "             [885*img.shape[1]/960, img.shape[0]],\n",
    "             [220*img.shape[1]/960, img.shape[0]]], dtype='f')\n",
    "        \n",
    "\n",
    "        # Next, we'll define a desired rectangle plane for the warped image.\n",
    "        # We'll choose 4 points where we want source points to end up \n",
    "        # This time we'll choose our points by eyeballing a rectangle\n",
    "\n",
    "        dst = np.array(\n",
    "            [[290*img.shape[1]/960, 0],\n",
    "             [740*img.shape[1]/960, 0],\n",
    "             [740*img.shape[1]/960, img.shape[0]],\n",
    "             [290*img.shape[1]/960, img.shape[0]]], dtype='f')\n",
    "\n",
    "\n",
    "        #Compute the perspective transform, M, given source and destination points:\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "        #Warp an image using the perspective transform, M; using linear interpolation    \n",
    "        #Interpolating points is just filling in missing points as it warps an image\n",
    "        # The input image for this function can be a colored image too\n",
    "        warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "              \n",
    "        return warped, src, dst \n",
    "\n",
    "    def rev_perspective_transform(img, src, dst):\n",
    "\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "        #Compute the perspective transform, M, given source and destination points:\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "        #Warp an image using the perspective transform, M; using linear interpolation    \n",
    "        #Interpolating points is just filling in missing points as it warps an image\n",
    "        # The input image for this function can be a colored image too\n",
    "        un_warped = cv2.warpPerspective(img, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "              \n",
    "        return un_warped \n",
    "\n",
    "    \n",
    "    def draw_polygon(img1, img2, src, dst):\n",
    "        src = src.astype(int)  #Very important step (Pixels cannot be in decimals)\n",
    "        dst = dst.astype(int)\n",
    "        cv2.polylines(img1, [src], True, (255,0,0), 3)\n",
    "        cv2.polylines(img2, [dst], True, (255,0,0), 3)\n",
    "    \n",
    "    def histogram_bottom_peaks (warped_img):\n",
    "        # This will detect the bottom point of our lane lines\n",
    "        \n",
    "        # Take a histogram of the bottom half of the image\n",
    "        bottom_half = warped_img[((2*warped_img.shape[0])//5):,:,0]     # Collecting all pixels in the bottom half\n",
    "        histogram = np.sum(bottom_half, axis=0)                         # Summing them along y axis (or along columns)\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]//2)        # 1D array hai histogram toh uska bas 0th index filled hoga \n",
    "        #print(np.shape(histogram))     #OUTPUT:(1280,)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        return leftx_base, rightx_base\n",
    "    \n",
    "    def find_lane_pixels(warped_img):\n",
    "    \n",
    "        leftx_base, rightx_base = histogram_bottom_peaks(warped_img)\n",
    "   \n",
    "        \n",
    "        # HYPERPARAMETERS\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set the width of the windows +/- margin. So width = 2*margin \n",
    "        margin = 90\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 1000    #I've changed this from 50 as given in lectures\n",
    "    \n",
    "        # Set height of windows - based on nwindows above and image shape\n",
    "        window_height = np.int(warped_img.shape[0]//nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = warped_img.nonzero()  #pixel ke coordinates dega 2 seperate arrays mein\n",
    "        nonzeroy = np.array(nonzero[0])    # Y coordinates milenge 1D array mein. They will we arranged in the order of pixels\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated later for each window in nwindows\n",
    "        leftx_current = leftx_base         #initially set kar diya hai. For loop ke end mein change karenge\n",
    "        rightx_current = rightx_base\n",
    "\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []   # Ismein lane-pixels ke indices collect karenge. \n",
    "                              # 'nonzerox' array mein index daalke coordinate mil jaayega\n",
    "        right_lane_inds = []  \n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = warped_img.shape[0] - (window+1)*window_height\n",
    "            win_y_high = warped_img.shape[0] - window*window_height\n",
    "            \"\"\"### TO-DO: Find the four below boundaries of the window ###\"\"\"\n",
    "            win_xleft_low = leftx_current - margin  \n",
    "            win_xleft_high = leftx_current + margin  \n",
    "            win_xright_low = rightx_current - margin  \n",
    "            win_xright_high = rightx_current + margin \n",
    "            \n",
    "            \"\"\"\n",
    "            # Create an output image to draw on and visualize the result\n",
    "            out_img = np.copy(warped_img)\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "            (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "            (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "            \"\"\"\n",
    "\n",
    "            ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "            #Iska poora explanation seperate page mein likha hai\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            # If you found > minpix pixels, recenter next window on the mean position of the pixels in your current window (re-centre)\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    \n",
    "        # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "        try:\n",
    "            left_lane_inds = np.concatenate(left_lane_inds)\n",
    "            right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        except ValueError:\n",
    "            # Avoids an error if the above is not implemented fully\n",
    "            pass\n",
    "    \n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        \"\"\"return leftx, lefty, rightx, righty, out_img\"\"\" #agar rectangles bana rahe ho toh out_image rakhna\n",
    "        return leftx, lefty, rightx, righty\n",
    "        \n",
    "\n",
    "    def fit_polynomial(warped_img, leftx, lefty, rightx, righty, right_history):\n",
    "    \n",
    "        #Fit a second order polynomial to each using `np.polyfit` ###\n",
    "        left_fit = np.polyfit(lefty,leftx,2)\n",
    "        right_fit = np.polyfit(righty,rightx,2)\n",
    "\n",
    "        # Generate x and y values for plotting. \n",
    "        #NOTE: y is the independent variable. Refer \"fit polynomial\" notes for explanation\n",
    "        # We'll plot x as a function of y\n",
    "        ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0])\n",
    "        \n",
    "        # Eqn of parabola: a(x**2) + bx + c. Where a and b denote the shape of parabola. Shape of parabola will be amost constant inn our case \n",
    "        \n",
    "        \n",
    "        try:        \n",
    "            left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "            \n",
    "            if(right_history == [0,0,0]):\n",
    "                a2 = (0.6*left_fit[0] + 0.4*right_fit[0])\n",
    "                b2 = (0.6*left_fit[1] + 0.4*right_fit[1])\n",
    "                c2 = (warped_img.shape[1] - (left_fit[0]*(warped_img.shape[0]-1)**2 + left_fit[1]*(warped_img.shape[0]-1) + left_fit[2]))*0.1 + 0.9*right_fit[2]\n",
    "\n",
    "            else:\n",
    "                a2_new = (0.6*left_fit[0] + 0.4*right_fit[0])\n",
    "                b2_new = (0.6*left_fit[1] + 0.4*right_fit[1])  \n",
    "                c2_new = (warped_img.shape[1] - (left_fit[0]*(warped_img.shape[0]-1)**2 + left_fit[1]*(warped_img.shape[0]-1) + left_fit[2]))*0.1 + 0.9*right_fit[2]\n",
    "                \n",
    "                a2_old= right_history[0]\n",
    "                b2_old= right_history[1]       \n",
    "                c2_old= right_history[2]\n",
    "                \n",
    "                a2= a2_new*0.3 + a2_old*0.7\n",
    "                b2= b2_new*0.3 + b2_old*0.7\n",
    "                c2= c2_new*0.3 + c2_old*0.7\n",
    "            \n",
    "            right_fitx = a2*ploty**2 + b2*ploty + c2\n",
    "            \n",
    "            status = True\n",
    "        \n",
    "        #try:\n",
    "        #    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        #    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "                \n",
    "        except TypeError:\n",
    "            # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "            print('The function failed to fit a line!')\n",
    "            left_fitx = 1*ploty**2 + 1*ploty\n",
    "            right_fitx = 1*ploty**2 + 1*ploty\n",
    "            status = False\n",
    "\n",
    "        \n",
    "        return left_fit, [a2,b2,c2], left_fitx, right_fitx, status\n",
    "        # out_img here has boxes drawn and the pixels are colored \n",
    "    \n",
    "    def color_pixels_and_curve(out_img, leftx, lefty, rightx, righty, left_fitx, right_fitx):\n",
    "        ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0])\n",
    "        ## Visualization ##\n",
    "        # Colors in the left and right lane regions\n",
    "        out_img[lefty, leftx] = [255, 0, 0]\n",
    "        out_img[righty, rightx] = [0, 0, 255]\n",
    "        \n",
    "        # Converting the coordinates of our line into integer values as index of the image can't take decimals\n",
    "        left_fitx_int = left_fitx.astype(np.int32)\n",
    "        right_fitx_int = right_fitx.astype(np.int32)\n",
    "        ploty_int = ploty.astype(np.int32)\n",
    "        \n",
    "        # Coloring the curve as yellow\n",
    "        out_img[ploty_int,left_fitx_int] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int] = [255,255,0]\n",
    "        \n",
    "        # To thicken the curve\n",
    "        out_img[ploty_int,left_fitx_int+1] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int+1] = [255,255,0]\n",
    "        out_img[ploty_int,left_fitx_int-1] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int-1] = [255,255,0]\n",
    "        out_img[ploty_int,left_fitx_int+2] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int+2] = [255,255,0]\n",
    "        out_img[ploty_int,left_fitx_int-2] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int-2] = [255,255,0]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def search_around_poly(warped_img, left_fit, right_fit):\n",
    "        # HYPERPARAMETER\n",
    "        # Choose the width of the margin around the previous polynomial to search\n",
    "        # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "        margin = 100\n",
    "\n",
    "        # Grab activated pixels\n",
    "        nonzero = warped_img.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        ### TO-DO: Set the area of search based on activated x-values ###\n",
    "        ### within the +/- margin of our polynomial function ###\n",
    "        ### Hint: consider the window areas for the similarly named variables ###\n",
    "        ### in the previous quiz, but change the windows to our new search area ###\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                        left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                        left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                        right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                        right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        return leftx, lefty, rightx, righty\n",
    "\n",
    "    \n",
    "    \n",
    "    undist_img = cal_undistort(frame)\n",
    "    thresh_img = thresh_img(undist_img)    # Note: This is not a binary iamge. It has been stacked already within the function\n",
    "    warped_img, src, dst = perspective_transform(thresh_img)\n",
    "\n",
    "    #draw_polygon(frame, warped_img, src, dst)   #the first image is the original image that you import into the system\n",
    "\n",
    "    if (lane.count == 0):\n",
    "        leftx, lefty, rightx, righty = find_lane_pixels(warped_img)     # Find our lane pixels first\n",
    "        left_fit, right_fit, left_fitx, right_fitx, status = fit_polynomial(warped_img, leftx, lefty, rightx, righty, right_history=[0,0,0])\n",
    "        \n",
    "    elif (lane.count > 0):\n",
    "        left_fit_previous = lane.current_fit[lane.count - 1][0]\n",
    "        right_fit_previous = lane.current_fit[lane.count - 1][1]\n",
    "        leftx, lefty, rightx, righty = search_around_poly(warped_img, left_fit_previous, right_fit_previous)\n",
    "        left_fit, right_fit, left_fitx, right_fitx, status = fit_polynomial(warped_img, leftx, lefty, rightx, righty, right_history=right_fit_previous)\n",
    "        \n",
    "    color_pixels_and_curve(warped_img, leftx, lefty, rightx, righty, left_fitx, right_fitx)\n",
    "    \n",
    "    lane.count = lane.count+1\n",
    "    lane.detected = status\n",
    "    lane.current_fit.append([left_fit, right_fit])\n",
    "    #lane.current_xfitted.append([left_fitx, right_fitx])\n",
    "    #lane.allx.append([leftx,rightx])\n",
    "    #lane.ally.append([lefty, righty])\n",
    "    #lane.image_output.append(warped_img)\n",
    "    \n",
    "    unwarped_img = rev_perspective_transform(warped_img, src, dst)\n",
    "    \n",
    "    return unwarped_img\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        #Let's count the number of consecutive frames\n",
    "        self.count = 0\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = []  \n",
    "        # x values of the curve that we fit intially\n",
    "        #self.current_xfitted = []\n",
    "        # x values for detected line pixels\n",
    "        #self.allx = []  \n",
    "        # y values for detected line pixels\n",
    "        #self.ally = []\n",
    "        #store your image in this\n",
    "        #self.image_output = []\n",
    "        \n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        \n",
    "        \n",
    "        \n",
    "lane=Line()\n",
    "\n",
    "\n",
    "frame1= mpimg.imread(\"my_test_images/Highway_snaps/image (1).jpg\")\n",
    "frame2= mpimg.imread(\"my_test_images/Highway_snaps/image (2).jpg\")\n",
    "frame3= mpimg.imread(\"my_test_images/Highway_snaps/image (3).jpg\")\n",
    "\n",
    "\n",
    "process_image(frame1)\n",
    "process_image(frame2)\n",
    "plt.imshow(process_image(frame3))\n",
    "\n",
    "print(lane.count)\n",
    "\n",
    "#print(np.shape(lane.image_output))\n",
    "#plt.imshow(lane.image_output[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Videoo test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/1260 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output_files/video_clips/project_video.mp4.\n",
      "Moviepy - Writing video output_files/video_clips/project_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output_files/video_clips/project_video.mp4\n",
      "Wall time: 6min 5s\n"
     ]
    }
   ],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        #Let's count the number of consecutive frames\n",
    "        self.count = 0\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = []  \n",
    "        # x values of the curve that we fit intially\n",
    "        #self.current_xfitted = []\n",
    "        # x values for detected line pixels\n",
    "        #self.allx = []  \n",
    "        # y values for detected line pixels\n",
    "        #self.ally = []\n",
    "        #store your image in this\n",
    "        #self.image_output = []\n",
    "        \n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float')      \n",
    "        \n",
    "lane=Line()\n",
    "\n",
    "project_output = 'output_files/video_clips/project_video.mp4'\n",
    "\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "#clip1 = VideoFileClip(\"project_video.mp4\").subclip(25,45)\n",
    "\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images! \n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output_files/video_clips/project_video.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
