{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the master pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Camera Caliberation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#%matplotlib notebook\n",
    "\n",
    "# Finding image and object points\n",
    "\n",
    "def undistort(test_img):\n",
    "# prepare object points (our ideal reference), like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "# Stores mtx and dist coefficients in a pickle file to use later\n",
    "    nx=9    # Number of inner corners of our chessboard along x axis (or columns)\n",
    "    ny=6    # Number of inner corners of our chessboard along y axis (or rows)\n",
    "\n",
    "    objp = np.zeros((ny*nx,3), np.float32)                  #We have 9 corners on X axis and 6 corners on Y axis\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)       # Gives us coorinate points in pairs as a list of 54 items. It's shape will be (54,2)       \n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space. These are the points for our ideal chessboard which we are using as a reference.       \n",
    "    imgpoints = [] # 2d points in image plane. We'll extract these from the images given for caliberating the camera\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        calib_img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(calib_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        # Grayscale conversion ensures an 8bit image as input.The next function needs that kind of input only. Generally color images are 24 bit images. (Refer \"Bits in images\" in notes) \n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)      # These will be same for caliberation image. The same points will get appended every time this fires up \n",
    "            imgpoints.append(corners)   # Corners \n",
    "            \n",
    "            # Draw and display the identified corners   (This step can be completely skipped)\n",
    "            cv2.drawChessboardCorners(calib_img, (nx,ny), corners, ret)\n",
    "            write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "            cv2.imwrite('output_files/corners_found_for_calib/'+write_name, calib_img)  \n",
    "            cv2.imshow(write_name, calib_img)  #We dont want to see the images now so commenting out. TO see output later, un-comment these 3 lines\n",
    "            cv2.waitKey(500)   #Delete after testing. These will be used to show you images one after the other\n",
    "\n",
    "    cv2.destroyAllWindows()   #Delete this after testing\n",
    "    \n",
    "    # Test undistortion on an image\n",
    "\n",
    "    test_img_size = (test_img.shape[1], test_img.shape[0])    # (x_axis_max)X(y_axis_max)\n",
    "    \n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, test_img_size,None,None)\n",
    "    \n",
    "    # Use the above obtained results to undistort \n",
    "    undist_img = cv2.undistort(test_img, mtx, dist, None, mtx)\n",
    "    \n",
    "    cv2.imwrite('output_files/test_undist.jpg',undist_img)\n",
    "    \n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    pickle.dump( dist_pickle, open( \"output_files/calib_pickle_files/dist_pickle.p\", \"wb\" ) )\n",
    "    \n",
    "    \"\"\"Caution: When you use mtx and dist later, ensure that the image used has same dimensions \n",
    "    as the images used here for caliberation, other we'll have to make some changes in the code\"\"\"\n",
    "    \n",
    "    #undist_img = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "    return undist_img\n",
    "    \n",
    "    \n",
    "\n",
    "test_img= cv2.imread('camera_cal/calibration1.jpg')    #Note: Your image will be in BGR format\n",
    "output=undistort(test_img)\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))        #Refer subplots in python libraries\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(output)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)\n",
    "cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Pipeline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import math\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def process_image(frame):\n",
    "    \n",
    "    def cal_undistort(img):\n",
    "        # Reads mtx and dist matrices, peforms image distortion correction and returns the undistorted image\n",
    "\n",
    "        import pickle\n",
    "\n",
    "        # Read in the saved matrices\n",
    "        my_dist_pickle = pickle.load( open( \"output_files/calib_pickle_files/dist_pickle.p\", \"rb\" ) )\n",
    "        mtx = my_dist_pickle[\"mtx\"]\n",
    "        dist = my_dist_pickle[\"dist\"]\n",
    "\n",
    "        undistorted_img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        #undistorted_img =  cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)   #Use if you use cv2 to import image. ax.imshow() needs RGB image\n",
    "        return undistorted_img\n",
    "\n",
    "    \n",
    "    def yellow_threshold(img, sxbinary):\n",
    "        # Convert to HLS color space and separate the S channel & H channel\n",
    "        # Note: img is the undistorted image\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        s_channel = hls[:,:,2]\n",
    "        h_channel = hls[:,:,0]\n",
    "        # Threshold color channel\n",
    "        s_thresh_min = 100\n",
    "        s_thresh_max = 255\n",
    "        \n",
    "        #for 360 degree, my desired values for yellow ranged between 35 and 50. Diving this range by 2:\n",
    "        h_thresh_min = 10    # Taking a bit lower than required to esnure that yellow is captured\n",
    "        h_thresh_max = 25\n",
    "\n",
    "        s_binary = np.zeros_like(s_channel)\n",
    "        s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "\n",
    "        h_binary = np.zeros_like(h_channel)\n",
    "        h_binary[(h_channel >= h_thresh_min) & (h_channel <= h_thresh_max)] = 1\n",
    "\n",
    "        # Combine the two binary thresholds\n",
    "        yellow_binary = np.zeros_like(s_binary)\n",
    "        yellow_binary[(((s_binary == 1) | (sxbinary == 1) ) & (h_binary ==1))] = 1\n",
    "        return yellow_binary\n",
    "    \n",
    "    def xgrad_binary(img, thresh_min=30, thresh_max=100):\n",
    "        # Grayscale image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # Sobel x\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "        abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "        scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "        # Threshold x gradient\n",
    "        #thresh_min = 30    # Given as default values to the parameters. These are good starting points\n",
    "        #thresh_max = 100   # The tweaked values are given as arguments to the function while calling it \n",
    "\n",
    "        sxbinary = np.zeros_like(scaled_sobel)\n",
    "        sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "        return sxbinary\n",
    "    \n",
    "    def white_threshold(img, sxbinary, lower_white_thresh = 170):\n",
    "        # Isolating RGB channel (as we've used matplotlib to read the image)\n",
    "        # The order would have been BGR if we had used cv2 to read the image\n",
    "        r_channel = img[:,:,0]\n",
    "        g_channel = img[:,:,1]\n",
    "        b_channel = img[:,:,2]\n",
    "        \n",
    "        # Threshold color channel\n",
    "        r_thresh_min = lower_white_thresh\n",
    "        r_thresh_max = 255\n",
    "        r_binary = np.zeros_like(r_channel)\n",
    "        r_binary[(r_channel >= r_thresh_min) & (r_channel <= r_thresh_max)] = 1\n",
    "        \n",
    "        g_thresh_min = lower_white_thresh\n",
    "        g_thresh_max = 255\n",
    "        g_binary = np.zeros_like(g_channel)\n",
    "        g_binary[(g_channel >= g_thresh_min) & (g_channel <= g_thresh_max)] = 1\n",
    "\n",
    "        b_thresh_min = lower_white_thresh\n",
    "        b_thresh_max = 255\n",
    "        b_binary = np.zeros_like(b_channel)\n",
    "        b_binary[(b_channel >= b_thresh_min) & (b_channel <= b_thresh_max)] = 1\n",
    "\n",
    "        white_binary = np.zeros_like(r_channel)\n",
    "        white_binary[((r_binary ==1) & (g_binary ==1) & (b_binary ==1) & (sxbinary==1))] = 1\n",
    "        return white_binary\n",
    "        \n",
    "    def thresh_img(img):\n",
    "                       \n",
    "        sxbinary = xgrad_binary(img, thresh_min=25, thresh_max=130)\n",
    "        yellow_binary = yellow_threshold(img, sxbinary)     #(((s) | (sx)) & (h))\n",
    "        white_binary = white_threshold(img, sxbinary, lower_white_thresh = 150)\n",
    "        \n",
    "        # Combine the two binary thresholds\n",
    "        combined_binary = np.zeros_like(sxbinary)\n",
    "        combined_binary[((yellow_binary == 1) | (white_binary == 1))] = 1\n",
    "        \n",
    "        # We close by sending out a 3D image just as we took as input \n",
    "        # Because, to process the image, we were using binary images\n",
    "        out_img = np.dstack((combined_binary, combined_binary, combined_binary))*255\n",
    "        \n",
    "        return out_img\n",
    "    \n",
    "    def perspective_transform(img):\n",
    "    \n",
    "        # Define calibration box in source (original) and destination (desired or warped) coordinates\n",
    "\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        \"\"\"Notice the format used for img_size. Yaha bhi ulta hai. x axis aur fir y axis chahiye. \n",
    "              Apne format mein rows(y axis) and columns (x axis) hain\"\"\"\n",
    "\n",
    "\n",
    "        # Four source coordinates\n",
    "        # Order of points: top left, top right, bottom right, bottom left\n",
    "        \n",
    "        src = np.array(\n",
    "            [[435*img.shape[1]/960, 350*img.shape[0]/540],\n",
    "             [530*img.shape[1]/960, 350*img.shape[0]/540],\n",
    "             [885*img.shape[1]/960, img.shape[0]],\n",
    "             [220*img.shape[1]/960, img.shape[0]]], dtype='f')\n",
    "        \n",
    "\n",
    "        # Next, we'll define a desired rectangle plane for the warped image.\n",
    "        # We'll choose 4 points where we want source points to end up \n",
    "        # This time we'll choose our points by eyeballing a rectangle\n",
    "\n",
    "        dst = np.array(\n",
    "            [[290*img.shape[1]/960, 0],\n",
    "             [740*img.shape[1]/960, 0],\n",
    "             [740*img.shape[1]/960, img.shape[0]],\n",
    "             [290*img.shape[1]/960, img.shape[0]]], dtype='f')\n",
    "\n",
    "\n",
    "        #Compute the perspective transform, M, given source and destination points:\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "        #Warp an image using the perspective transform, M; using linear interpolation    \n",
    "        #Interpolating points is just filling in missing points as it warps an image\n",
    "        # The input image for this function can be a colored image too\n",
    "        warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "              \n",
    "        return warped, src, dst \n",
    "\n",
    "    def rev_perspective_transform(img, src, dst):\n",
    "\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "        #Compute the perspective transform, M, given source and destination points:\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "        #Warp an image using the perspective transform, M; using linear interpolation    \n",
    "        #Interpolating points is just filling in missing points as it warps an image\n",
    "        # The input image for this function can be a colored image too\n",
    "        un_warped = cv2.warpPerspective(img, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "              \n",
    "        return un_warped, Minv \n",
    "\n",
    "    \n",
    "    def draw_polygon(img1, img2, src, dst):\n",
    "        src = src.astype(int)  #Very important step (Pixels cannot be in decimals)\n",
    "        dst = dst.astype(int)\n",
    "        cv2.polylines(img1, [src], True, (255,0,0), 3)\n",
    "        cv2.polylines(img2, [dst], True, (255,0,0), 3)\n",
    "    \n",
    "    def histogram_bottom_peaks (warped_img):\n",
    "        # This will detect the bottom point of our lane lines\n",
    "        \n",
    "        # Take a histogram of the bottom half of the image\n",
    "        bottom_half = warped_img[((2*warped_img.shape[0])//5):,:,0]     # Collecting all pixels in the bottom half\n",
    "        histogram = np.sum(bottom_half, axis=0)                         # Summing them along y axis (or along columns)\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]//2)        # 1D array hai histogram toh uska bas 0th index filled hoga \n",
    "        #print(np.shape(histogram))     #OUTPUT:(1280,)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        return leftx_base, rightx_base\n",
    "    \n",
    "    def find_lane_pixels(warped_img):\n",
    "    \n",
    "        leftx_base, rightx_base = histogram_bottom_peaks(warped_img)\n",
    "   \n",
    "        \n",
    "        # HYPERPARAMETERS\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set the width of the windows +/- margin. So width = 2*margin \n",
    "        margin = 90\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 1000    #I've changed this from 50 as given in lectures\n",
    "    \n",
    "        # Set height of windows - based on nwindows above and image shape\n",
    "        window_height = np.int(warped_img.shape[0]//nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = warped_img.nonzero()  #pixel ke coordinates dega 2 seperate arrays mein\n",
    "        nonzeroy = np.array(nonzero[0])    # Y coordinates milenge 1D array mein. They will we arranged in the order of pixels\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated later for each window in nwindows\n",
    "        leftx_current = leftx_base         #initially set kar diya hai. For loop ke end mein change karenge\n",
    "        rightx_current = rightx_base\n",
    "\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []   # Ismein lane-pixels ke indices collect karenge. \n",
    "                              # 'nonzerox' array mein index daalke coordinate mil jaayega\n",
    "        right_lane_inds = []  \n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = warped_img.shape[0] - (window+1)*window_height\n",
    "            win_y_high = warped_img.shape[0] - window*window_height\n",
    "            \"\"\"### TO-DO: Find the four below boundaries of the window ###\"\"\"\n",
    "            win_xleft_low = leftx_current - margin  \n",
    "            win_xleft_high = leftx_current + margin  \n",
    "            win_xright_low = rightx_current - margin  \n",
    "            win_xright_high = rightx_current + margin \n",
    "            \n",
    "            \"\"\"\n",
    "            # Create an output image to draw on and visualize the result\n",
    "            out_img = np.copy(warped_img)\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "            (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "            (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "            \"\"\"\n",
    "\n",
    "            ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "            #Iska poora explanation seperate page mein likha hai\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            # If you found > minpix pixels, recenter next window on the mean position of the pixels in your current window (re-centre)\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    \n",
    "        # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "        try:\n",
    "            left_lane_inds = np.concatenate(left_lane_inds)\n",
    "            right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        except ValueError:\n",
    "            # Avoids an error if the above is not implemented fully\n",
    "            pass\n",
    "    \n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        \"\"\"return leftx, lefty, rightx, righty, out_img\"\"\" #agar rectangles bana rahe ho toh out_image rakhna\n",
    "        return leftx, lefty, rightx, righty\n",
    "    \n",
    "        \n",
    "    def fit_polynomial(warped_img, leftx, lefty, rightx, righty, fit_history, variance_history):\n",
    "        \"\"\"This will fit a parabola on each lane line, give back lane curve coordinates, radius of curvature \"\"\"\n",
    "        \n",
    "        #Fit a second order polynomial to each using `np.polyfit` ###\n",
    "        left_fit = np.polyfit(lefty,leftx,2)\n",
    "        right_fit = np.polyfit(righty,rightx,2)\n",
    "\n",
    "        # We'll plot x as a function of y\n",
    "        ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0])\n",
    "        \n",
    "        \n",
    "        \"\"\"Primary coefficient detection: 1st level of curve fitting where frame naturally detects poins and fit's curve\"\"\"\n",
    "        #Steps: find a,b,c for our parabola: x=a(y^2)+b(y)+c\n",
    "        \"\"\"\n",
    "        1.a) If lane pixels found, fit a curve and get the coefficients for the left and right lane\n",
    "        1.b) If #pixels insuffient and curve couldn't be fit, use the curve from the previous frame if you have that data\n",
    "        (In case of lack of points in 1st frame, fit an arbitrary parabola with all coeff=1: Expected to improve later on)\n",
    "        \n",
    "        2) Using coefficient we'll fit a parabola. We'll improve it with following techiniques later on: \n",
    "        - Variance of lane pixels from parabola (to account for distance of curve points from the original pixels and attempt to minimise it)\n",
    "        - Shape and position of parabolas in the previous frame, \n",
    "        - Trends in radius of curvature, \n",
    "        - Frame mirroring (fine tuning one lane in the frame wrt to the other) \n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            a1_new= left_fit[0]\n",
    "            b1_new= left_fit[1]\n",
    "            c1_new= left_fit[2]\n",
    "            \n",
    "            a2_new= right_fit[0]\n",
    "            b2_new= right_fit[1]\n",
    "            c2_new= right_fit[2]\n",
    "            \n",
    "            #Calculate the x-coordinates of the parabola. Here x is the dependendent variable and y is independent\n",
    "            left_fitx = a1_new*ploty**2 + b1_new*ploty + c1_new\n",
    "            right_fitx = a2_new*ploty**2 + b2_new*ploty + c2_new\n",
    "            \n",
    "            status = True\n",
    "                \n",
    "        except TypeError:\n",
    "            # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "            print('The function failed to fit a line!')\n",
    "            \n",
    "            if(len(lane.curve_fit)!=5):    #If you dont have any values in the history\n",
    "                left_fitx = 1*ploty**2 + 1*ploty     #This is a senseless curve. If it was the 1st frame, we need to do something\n",
    "                right_fitx = 1*ploty**2 + 1*ploty\n",
    "            else:                                   #replicate lane from previous frame if you have history\n",
    "                left_fitx = fit_history[0][4][0]*ploty**2 + fit_history[0][4][1]*ploty + fit_history[0][4][2]\n",
    "                right_fitx = fit_history[1][4][0]*ploty**2 + fit_history[1][4][1]*ploty + fit_history[1][4][2]\n",
    "            lane.count=-1 #Restart your search in next frame. At the end of this frame, 1 gets added. Hence we'll get net 0. \n",
    "            \n",
    "            status = False\n",
    "    \n",
    "        \"\"\"VARIANCE: Average distance of lane pixels from our curve which we have fit\"\"\"\n",
    "        # Calculating variance for both lanes in the current frame. \n",
    "        # Even if current frame is the 1st frame, we still need the data for the further frames\n",
    "        # Hence it is calculated before the immediate next 'if' statement\n",
    "        \n",
    "        left_sum = 0 \n",
    "        for index in range(len(leftx)):\n",
    "            left_sum+= abs(leftx[index]-(a1_new*lefty[index]**2 + b1_new*lefty[index] + c1_new))\n",
    "        left_variance_new=left_sum/len(leftx)\n",
    "        \n",
    "                \n",
    "        right_sum=0\n",
    "        for index in range(len(rightx)):\n",
    "            right_sum+= abs(rightx[index]-(a2_new*righty[index]**2 + b2_new*righty[index] + c2_new))\n",
    "        right_variance_new=right_sum/len(rightx)\n",
    "                 \n",
    "        \n",
    "        #If you have history for variance and curve coefficients\n",
    "        \n",
    "        if((len(lane.curve_fit)==5)&(len(lane.variance)==5)):\n",
    "            \n",
    "            \n",
    "            left_variance_old = sum([(0.2*((5-index)**3)*element) for index,element in enumerate(variance_history[0])])/sum([0.2*((5-index)**3) for index in range(0,5)])\n",
    "            right_variance_old = sum([(0.2*((5-index)**3)*element) for index,element in enumerate(variance_history[1])])/sum([0.2*((5-index)**3) for index in range(0,5)])\n",
    "\n",
    "            \n",
    "            # Finding weighted average for the previous elements data within fit_history\n",
    "            a1_old= sum([(0.2*(index+1)*element[0]) for index,element in enumerate(fit_history[0])])/sum([0.2*(index+1) for index in range(0,5)])        \n",
    "            b1_old= sum([(0.2*(index+1)*element[1]) for index,element in enumerate(fit_history[0])])/sum([0.2*(index+1) for index in range(0,5)])       \n",
    "            c1_old= sum([(0.2*(index+1)*element[2]) for index,element in enumerate(fit_history[0])])/sum([0.2*(index+1) for index in range(0,5)])\n",
    "            a2_old= sum([(0.2*(index+1)*element[0]) for index,element in enumerate(fit_history[1])])/sum([0.2*(index+1) for index in range(0,5)])        \n",
    "            b2_old= sum([(0.2*(index+1)*element[1]) for index,element in enumerate(fit_history[1])])/sum([0.2*(index+1) for index in range(0,5)])       \n",
    "            c2_old= sum([(0.2*(index+1)*element[2]) for index,element in enumerate(fit_history[1])])/sum([0.2*(index+1) for index in range(0,5)])\n",
    "            \n",
    "            \n",
    "            a1_new = (a1_new*((left_variance_old)**2) + a1_old*((left_variance_new)**2))/(((left_variance_old)**2) + ((left_variance_new)**2)) \n",
    "            b1_new = (b1_new*((left_variance_old)**2) + b1_old*((left_variance_new)**2))/(((left_variance_old)**2) + ((left_variance_new)**2))\n",
    "            c1_new = (c1_new*((left_variance_old)**2) + c1_old*((left_variance_new)**2))/(((left_variance_old)**2) + ((left_variance_new))**2)\n",
    "            a2_new = (a2_new*((right_variance_old)**2) + a2_old*((right_variance_new)**2))/(((right_variance_old)**2) + ((right_variance_new))**2) \n",
    "            b2_new = (b2_new*((right_variance_old)**2) + b2_old*((right_variance_new)**2))/(((right_variance_old)**2) + ((right_variance_new))**2)\n",
    "            c2_new = (c2_new*((right_variance_old)**2) + c2_old*((right_variance_new)**2))/(((right_variance_old)**2) + ((right_variance_new))**2)\n",
    "\n",
    "            \n",
    "            ### Tracking the difference in curve fit coefficients over the frame  \n",
    "            # from last to last frame -> last frame\n",
    "            del_a1_old = lane.coeff_diff[0][0]\n",
    "            del_b1_old = lane.coeff_diff[0][1]\n",
    "            del_c1_old = lane.coeff_diff[0][2]\n",
    "            del_a2_old = lane.coeff_diff[1][0]\n",
    "            del_b2_old = lane.coeff_diff[1][1]\n",
    "            del_c2_old = lane.coeff_diff[1][2]\n",
    "            \n",
    "            # from last frame -> current frame \n",
    "            del_a1 = abs(a1_new - fit_history[0][4][0])   \n",
    "            del_b1 = abs(b1_new - fit_history[0][4][1])\n",
    "            del_c1 = abs(c1_new - fit_history[0][4][2])\n",
    "            del_a2 = abs(a2_new - fit_history[1][4][0])\n",
    "            del_b2 = abs(b2_new - fit_history[1][4][1])\n",
    "            del_c2 = abs(c2_new - fit_history[1][4][2])\n",
    "            \n",
    "            # Storing the new values so that the values can be used in the next frame\n",
    "            # As we are overwriting, the old values were called earlier & then the new values were found \n",
    "            lane.coeff_diff = [[del_a1, del_b1, del_c1], [del_a2, del_b2, del_c2]]\n",
    "\n",
    "            \n",
    "            # bas ab delta coefficient for each coefficient nikalna hai aur vo formula likh dena har element ke liye\n",
    "            a1_new = (a1_new*(del_a1_old) + a1_old*(del_a1))/((del_a1_old) + (del_a1))\n",
    "            b1_new = (b1_new*(del_b1_old) + b1_old*(del_b1))/((del_b1_old) + (del_b1))\n",
    "            c1_new = (c1_new*(del_c1_old) + c1_old*(del_c1))/((del_c1_old) + (del_c1))\n",
    "            a2_new = (a2_new*(del_a2_old) + a2_old*(del_a2))/((del_a2_old) + (del_a2))\n",
    "            b2_new = (b2_new*(del_b2_old) + b2_old*(del_b2))/((del_b2_old) + (del_b2))\n",
    "            c2_new = (c2_new*(del_c2_old) + c2_old*(del_c2))/((del_c2_old) + (del_c2))\n",
    "          \n",
    "                \n",
    "        \"\"\"FRAME MIRRORING: Fine tuning one lane wrt to the other same as they'll have similar curvature\"\"\"\n",
    "        # Steps: \n",
    "        \"\"\"\n",
    "        1) Weighted average of the coefficients related to curve shape (a,b) to make both parabola a bit similar\n",
    "        2) Adjusting the 'c' coefficient using the lane centre of previous frame and lane width acc to current frame\n",
    "        \"\"\"\n",
    "        \n",
    "        # We'll use lane centre for the previous frame to fine tune c of the parabola. First frame won't have a history so \n",
    "        # Just for the 1st frame, we'll define it according to itself and use. Won't make any impact but will set a base for the next frames \n",
    "        if (lane.count==0):\n",
    "            lane.lane_bottom_centre = (((a2_new*(warped_img.shape[0]-1)**2 + b2_new*(warped_img.shape[0]-1) + c2_new) + (a1_new*(warped_img.shape[0]-1)**2 + b1_new*(warped_img.shape[0]-1) + c1_new))/2) \n",
    "        \n",
    "        # We'll find lane width according to the latest curve coefficients till now \n",
    "        lane.lane_width = (((lane.lane_width*lane.count)+(a2_new*(warped_img.shape[0]-1)**2 + b2_new*(warped_img.shape[0]-1) + c2_new) - (a1_new*(warped_img.shape[0]-1)**2 + b1_new*(warped_img.shape[0]-1) + c1_new))/(lane.count+1))\n",
    "        \n",
    "        a1 = 0.8*a1_new + 0.2*a2_new\n",
    "        b1 = 0.8*b1_new + 0.2*b2_new\n",
    "        a2 = 0.2*a1_new + 0.8*a2_new\n",
    "        b2 = 0.2*b1_new + 0.8*b2_new\n",
    "                \n",
    "        # Taking the lane centre fromt the previous frame and finding \"c\" such that both lanes are equidistant from it.\n",
    "        c1_mirror = ((lane.lane_bottom_centre - (lane.lane_width/2))-(a1*(warped_img.shape[0]-1)**2 + b1*(warped_img.shape[0]-1)))\n",
    "        c2_mirror = ((lane.lane_bottom_centre + (lane.lane_width/2))-(a2*(warped_img.shape[0]-1)**2 + b2*(warped_img.shape[0]-1)))\n",
    "        \n",
    "        c1= 0.7*c1_new + 0.3*c1_mirror\n",
    "        c2 = 0.7*c2_new + 0.3*c2_mirror\n",
    "        \n",
    "        \n",
    "        # Now we'll find the lane centre of this frame and overwrite the global variable s that the next frame can use this value\n",
    "        lane.lane_bottom_centre = (((a2*(warped_img.shape[0]-1)**2 + b2*(warped_img.shape[0]-1) + c2) + (a1*(warped_img.shape[0]-1)**2 + b1*(warped_img.shape[0]-1) + c1))/2)\n",
    "        \n",
    "        #print(\"lane.lane_width\",lane.lane_width)\n",
    "        #print(\"lane.lane_bottom_centre\",lane.lane_bottom_centre)\n",
    "        \n",
    "        y_eval = np.max(ploty)\n",
    "\n",
    "        left_curverad = (((1 + (2*a1*y_eval + b1)**2)**1.5) / (2*a1))\n",
    "        right_curverad = (((1 + (2*a2*y_eval + b2)**2)**1.5) / (2*a2))\n",
    "        \n",
    "        left_fitx = a1*ploty**2 + b1*ploty + c1\n",
    "        right_fitx = a2*ploty**2 + b2*ploty + c2\n",
    "        \n",
    "        \n",
    "        return [[a1,b1,c1], [a2,b2,c2]], left_fitx, right_fitx, status, [left_variance_new, right_variance_new], ploty\n",
    "        \n",
    "             \n",
    "    def color_pixels_and_curve(out_img, leftx, lefty, rightx, righty, left_fitx, right_fitx):\n",
    "        ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0])\n",
    "        ## Visualization ##\n",
    "        # Colors in the left and right lane regions\n",
    "        out_img[lefty, leftx] = [255, 0, 0]\n",
    "        out_img[righty, rightx] = [0, 0, 255]\n",
    "        \n",
    "        # Converting the coordinates of our line into integer values as index of the image can't take decimals\n",
    "        left_fitx_int = left_fitx.astype(np.int32)\n",
    "        right_fitx_int = right_fitx.astype(np.int32)\n",
    "        ploty_int = ploty.astype(np.int32)\n",
    "        \n",
    "        # Coloring the curve as yellow\n",
    "        out_img[ploty_int,left_fitx_int] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int] = [255,255,0]\n",
    "        \n",
    "        # To thicken the curve, drawing more yellow lines\n",
    "        out_img[ploty_int,left_fitx_int+1] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int+1] = [255,255,0]\n",
    "        out_img[ploty_int,left_fitx_int-1] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int-1] = [255,255,0]\n",
    "        out_img[ploty_int,left_fitx_int+2] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int+2] = [255,255,0]\n",
    "        out_img[ploty_int,left_fitx_int-2] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int-2] = [255,255,0]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def search_around_poly(warped_img, left_fit, right_fit):\n",
    "        # HYPERPARAMETER\n",
    "        # Choosing the width of the margin around the previous polynomial to search\n",
    "        margin = 100\n",
    "\n",
    "        # Grab activated pixels\n",
    "        nonzero = warped_img.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        ### Setting the area of search based on activated x-values ###\n",
    "        ### within the +/- margin of our polynomial function ###\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                        left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                        left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                        right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                        right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        return leftx, lefty, rightx, righty\n",
    "\n",
    "    def modify_array(array, new_value):\n",
    "        if len(array)!=5:\n",
    "            for i in range(0,5):\n",
    "                array.append(new_value)\n",
    "\n",
    "        else:\n",
    "            dump_var=array[0]\n",
    "            array[0]=array[1]\n",
    "            array[1]=array[2]\n",
    "            array[2]=array[3]\n",
    "            array[3]=array[4]\n",
    "            array[4]=new_value\n",
    "        return array\n",
    "    \n",
    "    def truncate(number, digits) -> float:\n",
    "        stepper = 10.0 ** digits\n",
    "        return math.trunc(stepper * number) / stepper\n",
    "\n",
    "   \n",
    "    \"\"\"Main code begins here:\"\"\"\n",
    "    \n",
    "    undist_img = cal_undistort(frame)\n",
    "    thresh_img = thresh_img(undist_img)    # Note: Output here is not a binary image. It has been stacked already within the function\n",
    "    warped_img, src, dst = perspective_transform(thresh_img)\n",
    "\n",
    "    #draw_polygon(frame, warped_img, src, dst)   #the first image is the original image that you import into the system\n",
    "    \n",
    "    #print(\"starting count\",lane.count)\n",
    "    \n",
    "    # Making the curve coefficient, variance, radius of curvature history ready for our new frame. \n",
    "    left_fit_previous = [i[0] for i in lane.curve_fit] \n",
    "    right_fit_previous = [i[1] for i in lane.curve_fit]\n",
    "    fit_history=[left_fit_previous, right_fit_previous]\n",
    "        \n",
    "    left_variance_previous = [i[0] for i in lane.variance]\n",
    "    right_variance_previous = [i[1] for i in lane.variance]\n",
    "    variance_history=[left_variance_previous, right_variance_previous]\n",
    "    \n",
    "    # These variables realted to history could have been defined in condition lane.count>0 below\n",
    "    # Reason for defining above: We will want to get back to finding lane pixels from scratch  \n",
    "    # if our frame is a bad frame or the lane pixels deviate too much from the previous frame. \n",
    "    # In that case, we set lane.count=0 and start searching from scratch \n",
    "    # but we DO have history data at that point which will be used in fit_polnomial() function      \n",
    "    \n",
    "    if (lane.count == 0):\n",
    "        leftx, lefty, rightx, righty = find_lane_pixels(warped_img)     # Find our lane pixels first\n",
    "    elif (lane.count > 0):\n",
    "        leftx, lefty, rightx, righty = search_around_poly(warped_img, left_fit_previous[4], right_fit_previous[4])\n",
    "        \n",
    "    curve_fit_new, left_fitx, right_fitx, status, variance_new, ploty = fit_polynomial(warped_img, leftx, lefty, rightx, righty, fit_history, variance_history)\n",
    "    \n",
    "\n",
    "    \n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720     # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/650    # meters per pixel in x dimension\n",
    "    #Finding the fit for the curve fit who's constituent points: x and y have been caliberated \n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "    #Finding the correct radius of curvature in the real world frame (in metric system istead of pixel space) \n",
    "    \n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image (this is where we find roc)\n",
    "    y_eval = np.max(ploty)\n",
    "    left_curverad = (((1 + (2*left_fit_cr[0]*y_eval + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0]))\n",
    "    right_curverad = (((1 + (2*right_fit_cr[0]*y_eval + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0]))\n",
    "    avg_rad_curv = truncate(((left_curverad + right_curverad)/2),3)\n",
    "    \n",
    "    offset = truncate((((lane.lane_bottom_centre - frame.shape[1]/2))*xm_per_pix),3)\n",
    "    \n",
    "    #print(\"avg_rad_curv\",avg_rad_curv)\n",
    "    #print(\"offset\",offset)\n",
    "    \n",
    "    \n",
    "    lane.detected = status\n",
    "    lane.curve_fit = modify_array(lane.curve_fit, curve_fit_new)\n",
    "    lane.variance = modify_array(lane.variance, variance_new)\n",
    "    #print(lane.variance)\n",
    "                \n",
    "    # Now we'll color the lane pixels and plot the identified curve over the image    \n",
    "    #color_pixels_and_curve(warped_img, leftx, lefty, rightx, righty, left_fitx, right_fitx)\n",
    "    \n",
    "    unwarped_img, Minv = rev_perspective_transform(warped_img, src, dst)\n",
    "    \n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(warped_img).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (frame.shape[1], frame.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "\n",
    "    result = cv2.addWeighted(undist_img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    text1 = \"Curvature radius: \"+str(avg_rad_curv)+\"m\"\n",
    "    text2 = \"Offset: \"+str(offset)+\"m\"\n",
    "    cv2.putText(result, text1, (40, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), thickness=2)\n",
    "    cv2.putText(result, text2, (40, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), thickness=2)\n",
    "\n",
    "    \n",
    "    lane.count = lane.count+1  \n",
    "    \n",
    "    #return warped_img\n",
    "    #return color_warp\n",
    "    return result\n",
    "    #return unwarped_img\n",
    "    #return undist_img\n",
    "    #return thresh_img\n",
    "    #return warped_img\n",
    "    \"\"\"#color pixel function ko un-comment kardena\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class has been created below \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        #Let's count the number of consecutive frames\n",
    "        self.count = 0\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.curve_fit = []  \n",
    "        # Traking variance for the right lane\n",
    "        self.variance = []\n",
    "        #difference in fit coefficients between last and new fits. Just store the difference in coefficients for the last frame\n",
    "        self.coeff_diff = [[0,0,0],[0,0,0]]        \n",
    "        #Lane width measured at the start of reset\n",
    "        self.lane_width = 0\n",
    "        #Let's track the midpoint of the previous frame\n",
    "        self.lane_bottom_centre = 0\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "lane=Line()\n",
    "\n",
    "import glob\n",
    "\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(test_images):\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    #print (\"success\"+str(idx))\n",
    "    \n",
    "    write_name = 'output_files/img_results/undist_result '+str(idx+1)+'.jpg'\n",
    "    \n",
    "    color_corrected_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    \n",
    "    lane.count = 0  # Necessary otherwise the images will start fixing the curve according to the history\n",
    "    output = process_image(color_corrected_img)\n",
    "    output_mod = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    cv2.imwrite(write_name,output_mod)\n",
    "    cv2.imshow(write_name, output_mod)\n",
    "    cv2.waitKey(500)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "frame1= mpimg.imread(\"test_images/test (4).jpg\")\n",
    "\n",
    "\"\"\"\n",
    "frame2= mpimg.imread(\"my_test_images/Highway_snaps/image (2).jpg\")\n",
    "frame3= mpimg.imread(\"my_test_images/Highway_snaps/image (3).jpg\")\n",
    "\n",
    "frame4= mpimg.imread(\"my_test_images/Highway_snaps/image (4).jpg\")\n",
    "frame5= mpimg.imread(\"my_test_images/Highway_snaps/image (5).jpg\")\n",
    "frame6= mpimg.imread(\"my_test_images/Highway_snaps/image (6).jpg\")\n",
    "frame7= mpimg.imread(\"my_test_images/Highway_snaps/image (7).jpg\")\n",
    "frame8= mpimg.imread(\"my_test_images/Highway_snaps/image (8).jpg\")\n",
    "frame9= mpimg.imread(\"my_test_images/Highway_snaps/image (9).jpg\")\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "(process_image(frame1))\n",
    "(process_image(frame2))\n",
    "(process_image(frame3))\n",
    "(process_image(frame4))\n",
    "(process_image(frame5))\n",
    "(process_image(frame6))\n",
    "(process_image(frame7))\n",
    "(process_image(frame8))\n",
    "\"\"\"\n",
    "plt.imshow(process_image(frame1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        #Let's count the number of consecutive frames\n",
    "        self.count = 0\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.curve_fit = []  \n",
    "        # Traking variance for the right lane\n",
    "        self.variance = []\n",
    "        #difference in fit coefficients between last and new fits. Just store the difference in coefficients for the last frame\n",
    "        self.coeff_diff = [[0,0,0],[0,0,0]]       \n",
    "        #Lane width measured at the start of reset\n",
    "        self.lane_width = 0\n",
    "        #Let's track the midpoint of the previous frame\n",
    "        self.lane_bottom_centre = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "lane=Line()\n",
    "\n",
    "project_output = 'Project_Result_FINAL.mp4'\n",
    "\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\").subclip(17,26)\n",
    "\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images! \n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
