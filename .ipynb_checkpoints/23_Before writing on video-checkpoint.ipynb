{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the master pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "\n",
    "# Finding image and object points\n",
    "\n",
    "def undistort(test_img):\n",
    "# prepare object points (our ideal reference), like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "# Stores mtx and dist coefficients in a pickle file to use later\n",
    "    nx=9    # Number of inner corners of our chessboard along x axis (or columns)\n",
    "    ny=6    # Number of inner corners of our chessboard along y axis (or rows)\n",
    "\n",
    "    objp = np.zeros((ny*nx,3), np.float32)                  #We have 9 corners on X axis and 6 corners on Y axis\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)       # Gives us coorinate points in pairs as a list of 54 items. It's shape will be (54,2)       \n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space. These are the points for our ideal chessboard which we are using as a reference.       \n",
    "    imgpoints = [] # 2d points in image plane. We'll extract these from the images given for caliberating the camera\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for idx, fname in enumerate(images):\n",
    "        calib_img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(calib_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        # Grayscale conversion ensures an 8bit image as input.The next function needs that kind of input only. Generally color images are 24 bit images. (Refer \"Bits in images\" in notes) \n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)      # These will be same for caliberation image. The same points will get appended every time this fires up \n",
    "            imgpoints.append(corners)   # Corners \n",
    "            \n",
    "            # Draw and display the corners                                  #This step can be completely skipped\n",
    "            cv2.drawChessboardCorners(calib_img, (nx,ny), corners, ret)\n",
    "            write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "            cv2.imwrite('output_files/corners_found_for_calib/'+write_name, calib_img)  \n",
    "            cv2.imshow(write_name, calib_img)  #We dont want to see the images now so commenting out. TO see output later, un-comment these 3 lines\n",
    "            cv2.waitKey(500)   #Delete after testing. These will be used to show you images one after the other\n",
    "\n",
    "    cv2.destroyAllWindows()   #Delete this after testing\n",
    "    \n",
    "    # Test undistortion on an image\n",
    "\n",
    "    test_img_size = (test_img.shape[1], test_img.shape[0])\n",
    "    \n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, test_img_size,None,None)\n",
    "    \n",
    "    # Use the above obtained results to undistort \n",
    "    undist_img = cv2.undistort(test_img, mtx, dist, None, mtx)\n",
    "    \n",
    "    cv2.imwrite('output_files/test_undist.jpg',undist_img)\n",
    "    \n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    pickle.dump( dist_pickle, open( \"output_files/calib_pickle_files/dist_pickle.p\", \"wb\" ) )\n",
    "    #undist_img = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return undist_img\n",
    "    \n",
    "    \n",
    "\n",
    "test_img= cv2.imread('camera_cal/calibration1.jpg')    #Note: Your image will be in BGR format\n",
    "output=undistort(test_img)\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))        #Refer subplots in python libraries\n",
    "ax1.imshow(test_img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(output)\n",
    "ax2.set_title('Undistorted Image', fontsize=30)\n",
    "cv2.waitKey(500)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "def process_image(frame):\n",
    "    \n",
    "    def cal_undistort(img):\n",
    "        # Reads mtx and dist matrices, peforms image distortion correction and returns the undistorted image\n",
    "\n",
    "        import pickle\n",
    "\n",
    "        # Read in the saved matrices\n",
    "        my_dist_pickle = pickle.load( open( \"output_files/calib_pickle_files/dist_pickle.p\", \"rb\" ) )\n",
    "        mtx = my_dist_pickle[\"mtx\"]\n",
    "        dist = my_dist_pickle[\"dist\"]\n",
    "\n",
    "        undistorted_img = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        #undistorted_img =  cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)   #Use if you use cv2 to import image. ax.imshow() needs RGB image\n",
    "        return undistorted_img\n",
    "\n",
    "    \n",
    "    def yellow_threshold(img, sxbinary):\n",
    "        # Convert to HLS color space and separate the S channel\n",
    "        # Note: img is the undistorted image\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        s_channel = hls[:,:,2]\n",
    "        h_channel = hls[:,:,0]\n",
    "        # Threshold color channel\n",
    "        s_thresh_min = 100\n",
    "        s_thresh_max = 255\n",
    "        \n",
    "        #for 360 degree, my value for yellow ranged between 35 and 50. So uska half kar diya\n",
    "        h_thresh_min = 10    \n",
    "        h_thresh_max = 25\n",
    "\n",
    "        s_binary = np.zeros_like(s_channel)\n",
    "        s_binary[(s_channel >= s_thresh_min) & (s_channel <= s_thresh_max)] = 1\n",
    "\n",
    "        h_binary = np.zeros_like(h_channel)\n",
    "        h_binary[(h_channel >= h_thresh_min) & (h_channel <= h_thresh_max)] = 1\n",
    "\n",
    "        # Combine the two binary thresholds\n",
    "        yellow_binary = np.zeros_like(s_binary)\n",
    "        yellow_binary[(((s_binary == 1) | (sxbinary == 1) ) & (h_binary ==1))] = 1\n",
    "        return yellow_binary\n",
    "    \n",
    "    def xgrad_binary(img, thresh_min=30, thresh_max=100):\n",
    "        # Grayscale image\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # Sobel x\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "        abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "        scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "        # Threshold x gradient\n",
    "        #thresh_min = 30    #Already given above\n",
    "        #thresh_max = 100\n",
    "\n",
    "        sxbinary = np.zeros_like(scaled_sobel)\n",
    "        sxbinary[(scaled_sobel >= thresh_min) & (scaled_sobel <= thresh_max)] = 1\n",
    "        return sxbinary\n",
    "    \n",
    "    def white_threshold(img, sxbinary, lower_white_thresh = 170):\n",
    "        r_channel = img[:,:,0]\n",
    "        g_channel = img[:,:,1]\n",
    "        b_channel = img[:,:,2]\n",
    "        # Threshold color channel\n",
    "        r_thresh_min = lower_white_thresh\n",
    "        r_thresh_max = 255\n",
    "        r_binary = np.zeros_like(r_channel)\n",
    "        r_binary[(r_channel >= r_thresh_min) & (r_channel <= r_thresh_max)] = 1\n",
    "        \n",
    "        g_thresh_min = lower_white_thresh\n",
    "        g_thresh_max = 255\n",
    "        g_binary = np.zeros_like(g_channel)\n",
    "        g_binary[(g_channel >= g_thresh_min) & (g_channel <= g_thresh_max)] = 1\n",
    "\n",
    "        b_thresh_min = lower_white_thresh\n",
    "        b_thresh_max = 255\n",
    "        b_binary = np.zeros_like(b_channel)\n",
    "        b_binary[(b_channel >= b_thresh_min) & (b_channel <= b_thresh_max)] = 1\n",
    "\n",
    "        white_binary = np.zeros_like(r_channel)\n",
    "        white_binary[((r_binary ==1) & (g_binary ==1) & (b_binary ==1) & (sxbinary==1))] = 1\n",
    "        return white_binary\n",
    "        \n",
    "    def thresh_img(img):\n",
    "                       \n",
    "       \n",
    "        #sxbinary = xgrad_binary(img, thresh_min=30, thresh_max=100)\n",
    "        sxbinary = xgrad_binary(img, thresh_min=25, thresh_max=130)\n",
    "        yellow_binary = yellow_threshold(img, sxbinary)     #(((s) | (sx)) & (h))\n",
    "        white_binary = white_threshold(img, sxbinary, lower_white_thresh = 150)\n",
    "        \n",
    "        # Combine the two binary thresholds\n",
    "        combined_binary = np.zeros_like(sxbinary)\n",
    "        combined_binary[((yellow_binary == 1) | (white_binary == 1))] = 1\n",
    "        \n",
    "        out_img = np.dstack((combined_binary, combined_binary, combined_binary))*255\n",
    "        \n",
    "        return out_img\n",
    "    \n",
    "    def perspective_transform(img):\n",
    "    \n",
    "        # Define calibration box in source (original) and destination (desired or warped) coordinates\n",
    "\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "        \"\"\"Notice the format used for img_size. Yaha bhi ulta hai. x axis aur fir y axis chahiye. \n",
    "              Apne format mein rows(y axis) and columns (x axis) hain\"\"\"\n",
    "\n",
    "\n",
    "        # Four source coordinates\n",
    "        # Order of points: top left, top right, bottom right, bottom left\n",
    "        \n",
    "        src = np.array(\n",
    "            [[435*img.shape[1]/960, 350*img.shape[0]/540],\n",
    "             [530*img.shape[1]/960, 350*img.shape[0]/540],\n",
    "             [885*img.shape[1]/960, img.shape[0]],\n",
    "             [220*img.shape[1]/960, img.shape[0]]], dtype='f')\n",
    "        \n",
    "\n",
    "        # Next, we'll define a desired rectangle plane for the warped image.\n",
    "        # We'll choose 4 points where we want source points to end up \n",
    "        # This time we'll choose our points by eyeballing a rectangle\n",
    "\n",
    "        dst = np.array(\n",
    "            [[290*img.shape[1]/960, 0],\n",
    "             [740*img.shape[1]/960, 0],\n",
    "             [740*img.shape[1]/960, img.shape[0]],\n",
    "             [290*img.shape[1]/960, img.shape[0]]], dtype='f')\n",
    "\n",
    "\n",
    "        #Compute the perspective transform, M, given source and destination points:\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "\n",
    "        #Warp an image using the perspective transform, M; using linear interpolation    \n",
    "        #Interpolating points is just filling in missing points as it warps an image\n",
    "        # The input image for this function can be a colored image too\n",
    "        warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "              \n",
    "        return warped, src, dst \n",
    "\n",
    "    def rev_perspective_transform(img, src, dst):\n",
    "\n",
    "        img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "        #Compute the perspective transform, M, given source and destination points:\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "\n",
    "        #Warp an image using the perspective transform, M; using linear interpolation    \n",
    "        #Interpolating points is just filling in missing points as it warps an image\n",
    "        # The input image for this function can be a colored image too\n",
    "        un_warped = cv2.warpPerspective(img, Minv, img_size, flags=cv2.INTER_LINEAR)\n",
    "              \n",
    "        return un_warped, Minv \n",
    "\n",
    "    \n",
    "    def draw_polygon(img1, img2, src, dst):\n",
    "        src = src.astype(int)  #Very important step (Pixels cannot be in decimals)\n",
    "        dst = dst.astype(int)\n",
    "        cv2.polylines(img1, [src], True, (255,0,0), 3)\n",
    "        cv2.polylines(img2, [dst], True, (255,0,0), 3)\n",
    "    \n",
    "    def histogram_bottom_peaks (warped_img):\n",
    "        # This will detect the bottom point of our lane lines\n",
    "        \n",
    "        # Take a histogram of the bottom half of the image\n",
    "        bottom_half = warped_img[((2*warped_img.shape[0])//5):,:,0]     # Collecting all pixels in the bottom half\n",
    "        histogram = np.sum(bottom_half, axis=0)                         # Summing them along y axis (or along columns)\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]//2)        # 1D array hai histogram toh uska bas 0th index filled hoga \n",
    "        #print(np.shape(histogram))     #OUTPUT:(1280,)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        return leftx_base, rightx_base\n",
    "    \n",
    "    def find_lane_pixels(warped_img):\n",
    "    \n",
    "        leftx_base, rightx_base = histogram_bottom_peaks(warped_img)\n",
    "   \n",
    "        \n",
    "        # HYPERPARAMETERS\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set the width of the windows +/- margin. So width = 2*margin \n",
    "        margin = 90\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 1000    #I've changed this from 50 as given in lectures\n",
    "    \n",
    "        # Set height of windows - based on nwindows above and image shape\n",
    "        window_height = np.int(warped_img.shape[0]//nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = warped_img.nonzero()  #pixel ke coordinates dega 2 seperate arrays mein\n",
    "        nonzeroy = np.array(nonzero[0])    # Y coordinates milenge 1D array mein. They will we arranged in the order of pixels\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated later for each window in nwindows\n",
    "        leftx_current = leftx_base         #initially set kar diya hai. For loop ke end mein change karenge\n",
    "        rightx_current = rightx_base\n",
    "\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []   # Ismein lane-pixels ke indices collect karenge. \n",
    "                              # 'nonzerox' array mein index daalke coordinate mil jaayega\n",
    "        right_lane_inds = []  \n",
    "\n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = warped_img.shape[0] - (window+1)*window_height\n",
    "            win_y_high = warped_img.shape[0] - window*window_height\n",
    "            \"\"\"### TO-DO: Find the four below boundaries of the window ###\"\"\"\n",
    "            win_xleft_low = leftx_current - margin  \n",
    "            win_xleft_high = leftx_current + margin  \n",
    "            win_xright_low = rightx_current - margin  \n",
    "            win_xright_high = rightx_current + margin \n",
    "            \n",
    "            \"\"\"\n",
    "            # Create an output image to draw on and visualize the result\n",
    "            out_img = np.copy(warped_img)\n",
    "            # Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "            (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "            (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "            \"\"\"\n",
    "\n",
    "            ### TO-DO: Identify the nonzero pixels in x and y within the window ###\n",
    "            #Iska poora explanation seperate page mein likha hai\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "            (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            # If you found > minpix pixels, recenter next window on the mean position of the pixels in your current window (re-centre)\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    \n",
    "        # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "        try:\n",
    "            left_lane_inds = np.concatenate(left_lane_inds)\n",
    "            right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        except ValueError:\n",
    "            # Avoids an error if the above is not implemented fully\n",
    "            pass\n",
    "    \n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        \"\"\"return leftx, lefty, rightx, righty, out_img\"\"\" #agar rectangles bana rahe ho toh out_image rakhna\n",
    "        return leftx, lefty, rightx, righty\n",
    "    \n",
    "        \n",
    "    def fit_polynomial(warped_img, leftx, lefty, rightx, righty, fit_history, variance_history, rad_curv_history):\n",
    "        \"\"\"This will fit a parabola on each lane line, give back lane curve coordinates, radius of curvature \"\"\"\n",
    "        \n",
    "        #Fit a second order polynomial to each using `np.polyfit` ###\n",
    "        left_fit = np.polyfit(lefty,leftx,2)\n",
    "        right_fit = np.polyfit(righty,rightx,2)\n",
    "\n",
    "        # We'll plot x as a function of y\n",
    "        ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0])\n",
    "        \n",
    "        \n",
    "        \"\"\"Primary coefficient detection: 1st level of curve fitting where frame naturally detects poins and fit's curve\"\"\"\n",
    "        #Steps: find a,b,c for our parabola: x=a(y^2)+b(y)+c\n",
    "        \"\"\"\n",
    "        1.a) If lane pixels found, fit a curve and get the coefficients for the left and right lane\n",
    "        1.b) If #pixels insuffient and curve couldn't be fit, use the curve from the previous frame if you have that data\n",
    "        (In case of lack of points in 1st frame, fit an arbitrary parabola with all coeff=1: Expected to improve later on)\n",
    "        \n",
    "        2) Using coefficient we'll fit a parabola. We'll improve it with following techiniques later on: \n",
    "        - Variance lane pixels from parabola (to account for distance of curve points for )\n",
    "        - Shape and position of parabolas in the previous frame, \n",
    "        - Trends in radius of curvature, \n",
    "        - Frame mirroring (fine tuning one lane in the frame wrt to the other) \n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            a1_new= left_fit[0]\n",
    "            b1_new= left_fit[1]\n",
    "            c1_new= left_fit[2]\n",
    "            \n",
    "            a2_new= right_fit[0]\n",
    "            b2_new= right_fit[1]\n",
    "            c2_new= right_fit[2]\n",
    "            \n",
    "            #Calculate the x-coordinates of the parabola. Here x is the dependendent variable and y is independent\n",
    "            left_fitx = a1_new*ploty**2 + b1_new*ploty + c1_new\n",
    "            right_fitx = a2_new*ploty**2 + b2_new*ploty + c2_new\n",
    "            \n",
    "            status = True\n",
    "                \n",
    "        except TypeError:\n",
    "            # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "            print('The function failed to fit a line!')\n",
    "            \n",
    "            if(len(lane.curve_fit)!=5):    #If you dont have any values in the history\n",
    "                left_fitx = 1*ploty**2 + 1*ploty     #This is a senseless curve. If it was the 1st frame, we need to do something\n",
    "                right_fitx = 1*ploty**2 + 1*ploty\n",
    "            else:                                   #replicate lane from previous frame if you have history\n",
    "                left_fitx = fit_history[0][4][0]*ploty**2 + fit_history[0][4][1]*ploty + fit_history[0][4][2]\n",
    "                right_fitx = fit_history[1][4][0]*ploty**2 + fit_history[1][4][1]*ploty + fit_history[1][4][2]\n",
    "            lane.count=-1 #Restart your search in next frame. At the end of this frame, 1 gets added. Hence we'll get net 0. \n",
    "            \n",
    "            status = False\n",
    "    \n",
    "        \"\"\"VARIANCE: Average distance of lane pixels from our curve which we have fit\"\"\"\n",
    "        # Calculating variance for both lanes in the current frame    \n",
    "        left_sum = 0 \n",
    "        for index in range(len(leftx)):\n",
    "            left_sum+= abs(leftx[index]-(a1_new*lefty[index]**2 + b1_new*lefty[index] + c1_new))\n",
    "        left_variance_new=left_sum/len(leftx)\n",
    "        \n",
    "                \n",
    "        right_sum=0\n",
    "        for index in range(len(rightx)):\n",
    "            right_sum+= abs(rightx[index]-(a2_new*righty[index]**2 + b2_new*righty[index] + c2_new))\n",
    "        right_variance_new=right_sum/len(rightx)\n",
    "                 \n",
    "        \n",
    "        #If you have history for variance and curve coefficients\n",
    "        \n",
    "        if((len(lane.curve_fit)==5)&(len(lane.variance)==5)):\n",
    "            \n",
    "            \n",
    "            left_variance_old = sum([(0.2*((5-index)**3)*element) for index,element in enumerate(variance_history[0])])/sum([0.2*((5-index)**3) for index in range(0,5)])\n",
    "            right_variance_old = sum([(0.2*((5-index)**3)*element) for index,element in enumerate(variance_history[1])])/sum([0.2*((5-index)**3) for index in range(0,5)])\n",
    "\n",
    "            \n",
    "            # Finding weighted average for the previous elements data within fit_history\n",
    "            a1_old= sum([(0.2*(index+1)*element[0]) for index,element in enumerate(fit_history[0])])/sum([0.2*(index+1) for index in range(0,5)])        \n",
    "            b1_old= sum([(0.2*(index+1)*element[1]) for index,element in enumerate(fit_history[0])])/sum([0.2*(index+1) for index in range(0,5)])       \n",
    "            c1_old= sum([(0.2*(index+1)*element[2]) for index,element in enumerate(fit_history[0])])/sum([0.2*(index+1) for index in range(0,5)])\n",
    "            a2_old= sum([(0.2*(index+1)*element[0]) for index,element in enumerate(fit_history[1])])/sum([0.2*(index+1) for index in range(0,5)])        \n",
    "            b2_old= sum([(0.2*(index+1)*element[1]) for index,element in enumerate(fit_history[1])])/sum([0.2*(index+1) for index in range(0,5)])       \n",
    "            c2_old= sum([(0.2*(index+1)*element[2]) for index,element in enumerate(fit_history[1])])/sum([0.2*(index+1) for index in range(0,5)])\n",
    "            \n",
    "            \n",
    "            a1_new = (a1_new*((left_variance_old)**2) + a1_old*((left_variance_new)**2))/(((left_variance_old)**2) + ((left_variance_new)**2)) \n",
    "            b1_new = (b1_new*((left_variance_old)**2) + b1_old*((left_variance_new)**2))/(((left_variance_old)**2) + ((left_variance_new)**2))\n",
    "            c1_new = (c1_new*((left_variance_old)**2) + c1_old*((left_variance_new)**2))/(((left_variance_old)**2) + ((left_variance_new))**2)\n",
    "            a2_new = (a2_new*((right_variance_old)**2) + a2_old*((right_variance_new)**2))/(((right_variance_old)**2) + ((right_variance_new))**2) \n",
    "            b2_new = (b2_new*((right_variance_old)**2) + b2_old*((right_variance_new)**2))/(((right_variance_old)**2) + ((right_variance_new))**2)\n",
    "            c2_new = (c2_new*((right_variance_old)**2) + c2_old*((right_variance_new)**2))/(((right_variance_old)**2) + ((right_variance_new))**2)\n",
    "\n",
    "            \n",
    "            ### Tracking the difference in curve fit coefficients over the frame  \n",
    "            # from last to last frame -> last frame\n",
    "            del_a1_old = lane.coeff_diff[0][0]\n",
    "            del_b1_old = lane.coeff_diff[0][1]\n",
    "            del_c1_old = lane.coeff_diff[0][2]\n",
    "            del_a2_old = lane.coeff_diff[1][0]\n",
    "            del_b2_old = lane.coeff_diff[1][1]\n",
    "            del_c2_old = lane.coeff_diff[1][2]\n",
    "            \n",
    "            # from last frame -> current frame \n",
    "            del_a1 = abs(a1_new - fit_history[0][4][0])   \n",
    "            del_b1 = abs(b1_new - fit_history[0][4][1])\n",
    "            del_c1 = abs(c1_new - fit_history[0][4][2])\n",
    "            del_a2 = abs(a2_new - fit_history[1][4][0])\n",
    "            del_b2 = abs(b2_new - fit_history[1][4][1])\n",
    "            del_c2 = abs(c2_new - fit_history[1][4][2])\n",
    "            \n",
    "            lane.coeff_diff = [[del_a1, del_b1, del_c1], [del_a2, del_b2, del_c2]]\n",
    "\n",
    "            \n",
    "            \n",
    "            # bas ab delta coefficient for each coefficient nikalna hai aur vo formula likh dena har element ke liye\n",
    "            a1_new = (a1_new*(del_a1_old) + a1_old*(del_a1))/((del_a1_old) + (del_a1))\n",
    "            b1_new = (b1_new*(del_b1_old) + b1_old*(del_b1))/((del_b1_old) + (del_b1))\n",
    "            c1_new = (c1_new*(del_c1_old) + c1_old*(del_c1))/((del_c1_old) + (del_c1))\n",
    "            \"\"\"\n",
    "            #print(\"a2_new\",a2_new)\n",
    "            #print(\"b2_new\",b2_new)\n",
    "            #print(\"c2_new\",c2_new)\n",
    "            \"\"\"\n",
    "            a2_new = (a2_new*(del_a2_old) + a2_old*(del_a2))/((del_a2_old) + (del_a2))\n",
    "            b2_new = (b2_new*(del_b2_old) + b2_old*(del_b2))/((del_b2_old) + (del_b2))\n",
    "            c2_new = (c2_new*(del_c2_old) + c2_old*(del_c2))/((del_c2_old) + (del_c2))\n",
    "            \"\"\"          \n",
    "            #print(\"\")\n",
    "            #print(\"a2_old\",a2_old)\n",
    "            #print(\"b2_old\",b2_old)\n",
    "            #print(\"c2_old\",c2_old)\n",
    "            #print(\"\")\n",
    "            #print(\"a2_new\",a2_new)\n",
    "            #print(\"b2_new\",b2_new)\n",
    "            #print(\"c2_new\",c2_new)\n",
    "            \"\"\"\n",
    "        \n",
    "        y_eval = np.max(ploty)\n",
    "        # Calculation of R_curve (radius of curvature)\n",
    "        left_curverad = (((1 + (2*a1_new*y_eval + b1_new)**2)**1.5) / (2*a1_new))\n",
    "        right_curverad = (((1 + (2*a2_new*y_eval + b2_new)**2)**1.5) / (2*a2_new))\n",
    "        \n",
    "        if(len(lane.rad_curv)==5):\n",
    "            \"\"\"How to check series is decreasing or increasing\"\"\"\n",
    "     \n",
    "            slope_avg=0\n",
    "            for i in range(0,4):\n",
    "                slope_avg += ((slope_avg*i) + (rad_curv_history[0][i+1] - rad_curv_history[0][i]))/(i+1)\n",
    "            \n",
    "            # If this is not the point of inflection, and still the radius of curvature changes sign, discard the curve  \n",
    "            # Left\n",
    "            if (((rad_curv_history[0][4]>0) & (left_curverad<0) & (slope_avg>=0)) | ((rad_curv_history[0][4]<0) & (left_curverad>0) & (slope_avg<=0))):\n",
    "                a1_new = fit_history[0][4][0]\n",
    "                b1_new = fit_history[0][4][1]\n",
    "                c1_new = fit_history[0][4][2]\n",
    "\n",
    "            # Right    \n",
    "            if (((rad_curv_history[1][4]>0) & (right_curverad<0) & (slope_avg>=0)) | ((rad_curv_history[1][4]<0) & (right_curverad>0) & (slope_avg<=0))):\n",
    "                a2_new = fit_history[1][4][0]\n",
    "                b2_new = fit_history[1][4][1]\n",
    "                c2_new = fit_history[1][4][2]\n",
    "        \n",
    "        \n",
    "        \"\"\"FRAME MIRRORING: Fine tuning one lane wrt to the other same as they'll have similar curvature\"\"\"\n",
    "        #Steps: \n",
    "        \"\"\"\n",
    "        1) Weighted average of the coefficients related to curve shape (a,b) to make both parabola a bit similar\n",
    "        2) Adjusting the 'c' coefficient using the lane centre of previous frame and lane width acc to current frame\n",
    "        \"\"\"\n",
    "        \n",
    "        # We'll use lane centre for the previous frame to fine tune c of the parabola. First frame won't have a history so \n",
    "        # Just for the 1st frame, we'll define it according to itself and use. Won't make any impact but will set a base for the next frames \n",
    "        if (lane.count==0):\n",
    "            lane.lane_bottom_centre = (((a2_new*(warped_img.shape[0]-1)**2 + b2_new*(warped_img.shape[0]-1) + c2_new) + (a1_new*(warped_img.shape[0]-1)**2 + b1_new*(warped_img.shape[0]-1) + c1_new))/2) \n",
    "        \n",
    "        # We'll find lane width according to the latest curve coefficients till now \n",
    "        lane.lane_width = (((lane.lane_width*lane.count)+(a2_new*(warped_img.shape[0]-1)**2 + b2_new*(warped_img.shape[0]-1) + c2_new) - (a1_new*(warped_img.shape[0]-1)**2 + b1_new*(warped_img.shape[0]-1) + c1_new))/(lane.count+1))\n",
    "        \n",
    "        a1 = 0.8*a1_new + 0.2*a2_new\n",
    "        b1 = 0.8*b1_new + 0.2*b2_new\n",
    "        a2 = 0.2*a1_new + 0.8*a2_new\n",
    "        b2 = 0.2*b1_new + 0.8*b2_new\n",
    "        \n",
    "        #c1 = 0.8*c1_new + 0.2*c2_new\n",
    "        #c2 = 0.2*c1_new + 0.8*c2_new\n",
    "        \n",
    "        #T Taking the lane centre fromt the previous frame and finding \"c\" such that both lanes are equidistant from it.\n",
    "        c1_mirror = ((lane.lane_bottom_centre - (lane.lane_width/2))-(a1*(warped_img.shape[0]-1)**2 + b1*(warped_img.shape[0]-1)))\n",
    "        c2_mirror = ((lane.lane_bottom_centre + (lane.lane_width/2))-(a2*(warped_img.shape[0]-1)**2 + b2*(warped_img.shape[0]-1)))\n",
    "        \n",
    "        c1= 0.7*c1_new + 0.3*c1_mirror\n",
    "        c2 = 0.7*c2_new + 0.3*c2_mirror\n",
    "        \n",
    "        \n",
    "        # Now we'll find the lane centre of this frame and overwrite the global variable s that the next frame can use this value\n",
    "        lane.lane_bottom_centre = (((a2*(warped_img.shape[0]-1)**2 + b2*(warped_img.shape[0]-1) + c2) + (a1*(warped_img.shape[0]-1)**2 + b1*(warped_img.shape[0]-1) + c1))/2)\n",
    "        \n",
    "        #print(\"lane.lane_width\",lane.lane_width)\n",
    "        #print(\"lane.lane_bottom_centre\",lane.lane_bottom_centre)\n",
    "        \n",
    "        \n",
    "        left_curverad = (((1 + (2*a1*y_eval + b1)**2)**1.5) / (2*a1))\n",
    "        right_curverad = (((1 + (2*a2*y_eval + b2)**2)**1.5) / (2*a2))\n",
    "        \n",
    "        left_fitx = a1*ploty**2 + b1*ploty + c1\n",
    "        right_fitx = a2*ploty**2 + b2*ploty + c2\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"left_curverad\",left_curverad)\n",
    "        print(\"left_curverad\",right_curverad)\n",
    "        \n",
    "        print(\"a2\",a2)\n",
    "        print(\"b2\",b2)\n",
    "        print(\"c2\",c2)\n",
    "        \n",
    "        print(\"\")\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        return [[a1,b1,c1], [a2,b2,c2]], left_fitx, right_fitx, status, [left_variance_new, right_variance_new], [left_curverad,right_curverad], ploty\n",
    "        # out_img here has boxes drawn and the pixels are colored \n",
    "        \n",
    "        #return [[a1_new,b1_new,c1_new], [a2_new,b2_new,c2_new]], left_fitx, right_fitx, status, [left_variance_new, right_variance_new], ploty \n",
    "        \n",
    "      \n",
    "    def color_pixels_and_curve(out_img, leftx, lefty, rightx, righty, left_fitx, right_fitx):\n",
    "        ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0])\n",
    "        ## Visualization ##\n",
    "        # Colors in the left and right lane regions\n",
    "        out_img[lefty, leftx] = [255, 0, 0]\n",
    "        out_img[righty, rightx] = [0, 0, 255]\n",
    "        \n",
    "        # Converting the coordinates of our line into integer values as index of the image can't take decimals\n",
    "        left_fitx_int = left_fitx.astype(np.int32)\n",
    "        right_fitx_int = right_fitx.astype(np.int32)\n",
    "        ploty_int = ploty.astype(np.int32)\n",
    "        \n",
    "        # Coloring the curve as yellow\n",
    "        out_img[ploty_int,left_fitx_int] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int] = [255,255,0]\n",
    "        \n",
    "        # To thicken the curve\n",
    "        out_img[ploty_int,left_fitx_int+1] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int+1] = [255,255,0]\n",
    "        out_img[ploty_int,left_fitx_int-1] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int-1] = [255,255,0]\n",
    "        out_img[ploty_int,left_fitx_int+2] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int+2] = [255,255,0]\n",
    "        out_img[ploty_int,left_fitx_int-2] = [255,255,0]\n",
    "        out_img[ploty_int,right_fitx_int-2] = [255,255,0]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def search_around_poly(warped_img, left_fit, right_fit):\n",
    "        # HYPERPARAMETER\n",
    "        # Choose the width of the margin around the previous polynomial to search\n",
    "        # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "        margin = 100\n",
    "\n",
    "        # Grab activated pixels\n",
    "        nonzero = warped_img.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        ### TO-DO: Set the area of search based on activated x-values ###\n",
    "        ### within the +/- margin of our polynomial function ###\n",
    "        ### Hint: consider the window areas for the similarly named variables ###\n",
    "        ### in the previous quiz, but change the windows to our new search area ###\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "                        left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "                        left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "                        right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "                        right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        return leftx, lefty, rightx, righty\n",
    "\n",
    "    def modify_array(array, new_value):\n",
    "        if len(array)!=5:\n",
    "            for i in range(0,5):\n",
    "                array.append(new_value)\n",
    "\n",
    "        else:\n",
    "            dump_var=array[0]\n",
    "            array[0]=array[1]\n",
    "            array[1]=array[2]\n",
    "            array[2]=array[3]\n",
    "            array[3]=array[4]\n",
    "            array[4]=new_value\n",
    "        return array\n",
    "    \n",
    "   \n",
    "\n",
    "    undist_img = cal_undistort(frame)\n",
    "    thresh_img = thresh_img(undist_img)    # Note: This is not a binary iamge. It has been stacked already within the function\n",
    "    warped_img, src, dst = perspective_transform(thresh_img)\n",
    "\n",
    "    #draw_polygon(frame, warped_img, src, dst)   #the first image is the original image that you import into the system\n",
    "    \n",
    "    #print(\"starting count\",lane.count)\n",
    "    \n",
    "    # Making the curve coefficient and variance history ready for our new frame\n",
    "    left_fit_previous = [i[0] for i in lane.curve_fit] \n",
    "    right_fit_previous = [i[1] for i in lane.curve_fit]\n",
    "    fit_history=[left_fit_previous, right_fit_previous]\n",
    "        \n",
    "    left_variance_previous = [i[0] for i in lane.variance]\n",
    "    right_variance_previous = [i[1] for i in lane.variance]\n",
    "    variance_history=[left_variance_previous, right_variance_previous]\n",
    "    \n",
    "    left_rad_curv_prev = [i[0] for i in lane.rad_curv]\n",
    "    right_rad_curv_prev = [i[1] for i in lane.rad_curv]\n",
    "    rad_curv_history = [left_rad_curv_prev, right_rad_curv_prev]\n",
    "    #print(rad_curv_history)\n",
    "    \n",
    "    if (lane.count == 0):\n",
    "        leftx, lefty, rightx, righty = find_lane_pixels(warped_img)     # Find our lane pixels first\n",
    "    elif (lane.count > 0):\n",
    "        leftx, lefty, rightx, righty = search_around_poly(warped_img, left_fit_previous[4], right_fit_previous[4])\n",
    "        \n",
    "    curve_fit_new, left_fitx, right_fitx, status, variance_new, rad_curv_new,ploty = fit_polynomial(warped_img, leftx, lefty, rightx, righty, fit_history, variance_history,rad_curv_history)\n",
    "    \n",
    "    \n",
    "    \n",
    "    lane.rad_curv = modify_array(lane.rad_curv, rad_curv_new)\n",
    "    lane.detected = status\n",
    "    lane.curve_fit = modify_array(lane.curve_fit, curve_fit_new)\n",
    "    lane.variance = modify_array(lane.variance, variance_new)\n",
    "    #print(lane.variance)\n",
    "                \n",
    "    # Now we'll color the lane pixels and plot the identified curve over the image    \n",
    "    #color_pixels_and_curve(warped_img, leftx, lefty, rightx, righty, left_fitx, right_fitx)\n",
    "    \n",
    "    unwarped_img, Minv = rev_perspective_transform(warped_img, src, dst)\n",
    "    \n",
    "    \n",
    "    # Create an image to draw the lines on\n",
    "    color_warp = np.zeros_like(warped_img).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (frame.shape[1], frame.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "\n",
    "    result = cv2.addWeighted(undist_img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "\n",
    "    lane.count = lane.count+1  \n",
    "    \n",
    "    #return warped_img\n",
    "    #return color_warp\n",
    "    #return result\n",
    "    #return unwarped_img\n",
    "    #return undist_img\n",
    "    #return thresh_img\n",
    "    return warped_img\n",
    "    \"\"\"#color pixel funcction ko un-comment kardena\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class has been created below \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f486c37f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        #Let's count the number of consecutive frames\n",
    "        self.count = 0\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.curve_fit = []  \n",
    "        # Traking variance for the right lane\n",
    "        self.variance = []\n",
    "        #difference in fit coefficients between last and new fits. Just store the difference in coefficients for the last frame\n",
    "        self.coeff_diff = [[0,0,0],[0,0,0]]        \n",
    "        #Lane width measured at the start of reset\n",
    "        self.lane_width = 0\n",
    "        #Let's track the midpoint of the previous frame\n",
    "        self.lane_bottom_centre = 0\n",
    "        #radius of curvature of the line in some units\n",
    "        self.rad_curv = []\n",
    "        \n",
    "        # x values of the curve that we fit intially\n",
    "        #self.current_xfitted = []\n",
    "        # x values for detected line pixels\n",
    "        #self.allx = []  \n",
    "        # y values for detected line pixels\n",
    "        #self.ally = []\n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        \n",
    "        \n",
    "        \n",
    "lane=Line()\n",
    "\n",
    "import glob\n",
    "\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(test_images):\n",
    "    img = cv2.imread(fname)\n",
    "    \n",
    "    #print (\"success\"+str(idx))\n",
    "    \n",
    "    write_name = 'output_files/img_results/boxed_warped_result '+str(idx+1)+'.jpg'\n",
    "    \n",
    "    color_corrected_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    \n",
    "    lane.count = 0  # Necessary otherwise the images will start fixing the curve according to the history\n",
    "    output = process_image(color_corrected_img)\n",
    "    output_mod = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    cv2.imwrite(write_name,output_mod)\n",
    "    cv2.imshow(write_name, output_mod)\n",
    "    cv2.waitKey(500)\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "frame1= mpimg.imread(\"test_images/test (4).jpg\")\n",
    "\n",
    "\"\"\"\n",
    "frame2= mpimg.imread(\"my_test_images/Highway_snaps/image (2).jpg\")\n",
    "frame3= mpimg.imread(\"my_test_images/Highway_snaps/image (3).jpg\")\n",
    "\n",
    "frame4= mpimg.imread(\"my_test_images/Highway_snaps/image (4).jpg\")\n",
    "frame5= mpimg.imread(\"my_test_images/Highway_snaps/image (5).jpg\")\n",
    "frame6= mpimg.imread(\"my_test_images/Highway_snaps/image (6).jpg\")\n",
    "frame7= mpimg.imread(\"my_test_images/Highway_snaps/image (7).jpg\")\n",
    "frame8= mpimg.imread(\"my_test_images/Highway_snaps/image (8).jpg\")\n",
    "frame9= mpimg.imread(\"my_test_images/Highway_snaps/image (9).jpg\")\n",
    "\n",
    "%matplotlib notebook\n",
    "\n",
    "(process_image(frame1))\n",
    "(process_image(frame2))\n",
    "(process_image(frame3))\n",
    "(process_image(frame4))\n",
    "(process_image(frame5))\n",
    "(process_image(frame6))\n",
    "(process_image(frame7))\n",
    "(process_image(frame8))\n",
    "\"\"\"\n",
    "plt.imshow(process_image(frame1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "t:   0%|          | 0/1260 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video Project_Result.mp4.\n",
      "Moviepy - Writing video Project_Result.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready Project_Result.mp4\n",
      "Wall time: 36min 59s\n"
     ]
    }
   ],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        #Let's count the number of consecutive frames\n",
    "        self.count = 0\n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.curve_fit = []  \n",
    "        # Traking variance for the right lane\n",
    "        self.variance = []\n",
    "        #difference in fit coefficients between last and new fits. Just store the difference in coefficients for the last frame\n",
    "        self.coeff_diff = [[0,0,0],[0,0,0]]       \n",
    "        #Lane width measured at the start of reset\n",
    "        self.lane_width = 0\n",
    "        #Let's track the midpoint of the previous frame\n",
    "        self.lane_bottom_centre = 0\n",
    "        #radius of curvature of the line in some units\n",
    "        self.rad_curv = []\n",
    "        \n",
    "        \n",
    "        # x values of the curve that we fit intially\n",
    "        #self.current_xfitted = []\n",
    "        # x values for detected line pixels\n",
    "        #self.allx = []  \n",
    "        # y values for detected line pixels\n",
    "        #self.ally = []\n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = [] \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None     \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None  \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        \n",
    "lane=Line()\n",
    "\n",
    "project_output = 'Project_Result.mp4'\n",
    "\n",
    "clip1 = VideoFileClip(\"test_videos/project_video.mp4\")\n",
    "\n",
    "project_clip = clip1.fl_image(process_image) #NOTE: this function expects color images! \n",
    "%time project_clip.write_videofile(project_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"Project_Result.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(project_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
